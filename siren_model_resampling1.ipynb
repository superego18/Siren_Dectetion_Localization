{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59826ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 226152721070306616\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4298113024\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13606944259739188919\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:07:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21bcba8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu 개수는: 8\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Conv2D, MaxPooling2D, Dropout, Add, BatchNormalization, Activation, Reshape\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, precision_recall_curve, mean_squared_error\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "my_seed = 1027\n",
    "\n",
    "tf.random.set_seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "\n",
    "import librosa\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import csv\n",
    "\n",
    "from tqdm import tqdm\n",
    "def tqdm_close():\n",
    "    for instance in tqdm._instances:\n",
    "        instance.close()\n",
    "import multiprocessing as mp\n",
    "print('cpu 개수는:', mp.cpu_count())\n",
    "from joblib import Parallel, delayed        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15129578",
   "metadata": {},
   "outputs": [],
   "source": [
    "### make input file list\n",
    "def get_file_list(cls):\n",
    "    if cls == 1:\n",
    "        folder_path = 'dataset' # siren\n",
    "    else:\n",
    "        folder_path = 'dataset2' # others\n",
    "    file_list = os.listdir(folder_path)\n",
    "    return file_list\n",
    "\n",
    "def rsp_50to20k(original_array): # shape: (4,100)\n",
    "    rsp_array_list = []\n",
    "    fre_array_list = []\n",
    "    for array in original_array:\n",
    "        rsp_array = np.round(librosa.resample(array, orig_sr=50, target_sr=5000), 3)\n",
    "        rsp_array_list.append(rsp_array)\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=rsp_array, sr=5000, n_mels=64, hop_length=101, win_length=2048)\n",
    "        log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "        mfcc = librosa.feature.mfcc(S=log_mel_spectrogram, sr=5000, n_mfcc= 36)\n",
    "        fre_array_list.append(np.round(np.vstack((log_mel_spectrogram, mfcc)), 3))\n",
    "    sum_array = np.sum(np.array(rsp_array_list), axis=0)\n",
    "    return np.array(rsp_array_list), sum_array, np.round(rsp_array/sum_array*100, 3), np.array(fre_array_list)\n",
    "\n",
    "def np_ast(str_list):\n",
    "    return np.array(ast.literal_eval(str_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2434df47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 312/312 [00:44<00:00,  7.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 443/443 [01:23<00:00,  5.30it/s]\n"
     ]
    }
   ],
   "source": [
    "ch_rsp_list, ch_rt_list = [], []\n",
    "label1_list, label2_list = [], []\n",
    "fre_list = []\n",
    "\n",
    "for cls in [0, 1]:  \n",
    "    \n",
    "    if cls == 1:\n",
    "        folder_path = 'dataset'\n",
    "    else:\n",
    "        folder_path = 'dataset2'\n",
    "    file_list = get_file_list(cls)  \n",
    "\n",
    "    for i in tqdm(range(len(file_list))):\n",
    "        x = float(file_list[i].split('.')[0].split('_')[0])\n",
    "        y = float(file_list[i].split('.')[0].split('_')[1])\n",
    "\n",
    "        dt = round(np.sqrt(x**2 + y**2), 1)\n",
    "        theta = np.arctan2(y, x)\n",
    "        deg = round(theta * (180 / np.pi), 1)\n",
    "        cos_val = round(np.cos(theta), 2)\n",
    "        sin_val = round(np.sin(theta), 2)\n",
    "\n",
    "        df_to_prcs = pd.read_csv(f'{folder_path}/{file_list[i]}')\n",
    "\n",
    "        for j in range(0,151,25):\n",
    "            df_sub = df_to_prcs.iloc[j:j+100, :]\n",
    "            ch_rsp, sum_rsp, ch_rt, fre = rsp_50to20k(df_sub.iloc[:, :4].T.values.astype(float))\n",
    "\n",
    "            \n",
    "            ch_rsp_list.append(ch_rsp)\n",
    "            ch_rt_list.append(np.array(np.vstack((ch_rt, sum_rsp))))\n",
    "                              \n",
    "            fre_list.append(fre)\n",
    "            \n",
    "            label1_list.append(np.array([x, y, cls]))\n",
    "            label2_list.append(np.array([sin_val, cos_val, dt, cls]))\n",
    "\n",
    "tqdm_close()\n",
    "\n",
    "ch_rsp_list_tr, ch_rt_list_tr = np.array(ch_rsp_list), np.array(ch_rt_list)\n",
    "label1_list_tr, label2_list_tr = np.array(label1_list), np.array(label2_list)\n",
    "fre_list_tr = np.array(fre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f3599d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 4, 10000, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 4, 10000, 10  200         ['input_1[0][0]']                \n",
      "                                0)                                                                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 4, 10000, 10  10100       ['conv2d[0][0]']                 \n",
      "                                0)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 4, 100, 100)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose (TFOpLa  (None, 100, 100, 4)  0          ['max_pooling2d[0][0]']          \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 100, 100, 4  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 49, 49, 32)   2080        ['tf.compat.v1.transpose[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 49, 49, 32)   2080        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 23, 23, 32)   16416       ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 23, 23, 32)   16416       ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 11, 11, 32)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 11, 11, 32)  0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 3872)         0           ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 3872)         0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 3872)         0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          1982976     ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           32832       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 3)            195         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,063,295\n",
      "Trainable params: 2,063,295\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# input layer\n",
    "input_shape_1 = (4, 10000, 1) # resampling raw data\n",
    "input_shape_2 = (100, 100, 4) # frequency featuring\n",
    "\n",
    "input_layer_1 = Input(shape=input_shape_1)\n",
    "input_layer_2 = Input(shape=input_shape_2)\n",
    "\n",
    "# 1D CONV # raw feature extract\n",
    "# filter  100개로 -> log mel spectrogram + mfcc의 구성 요소 수와 동일 : 각 필터가 주파수 특성과 연관\n",
    "x1 = Conv2D(100, (1, 1), activation='relu')(input_layer_1) # (4ch, 10000t, 100feature)\n",
    "x1 = Conv2D(100, (1, 1), activation='relu')(x1) # (4, 10000, 100)\n",
    "x1 = MaxPooling2D((1, 100))(x1) # (4, 100t, 100f)\n",
    "x1 = tf.transpose(x1, perm=[0, 3, 2, 1]) # (100f, 100t, 4)\n",
    "\n",
    "# MLnet\n",
    "x1 = Conv2D(32, (4, 4), (2, 2), activation='relu')(x1) # (49, 49, 32)\n",
    "x1 = Conv2D(32, (4, 4), (2, 2), activation='relu')(x1) # (23, 23, 32)\n",
    "x1 = MaxPooling2D((2, 2), (2, 2))(x1) #(11, 11, 32)\n",
    "x1 = Flatten()(x1) #(3872)\n",
    "\n",
    "# MLnet\n",
    "x2 = Conv2D(32, (4, 4), (2, 2), activation='relu')(input_layer_2) # (49, 49, 32)\n",
    "x2 = Conv2D(32, (4, 4), (2, 2), activation='relu')(x2) # (23, 23, 32)\n",
    "x2 = MaxPooling2D((2, 2), (2, 2))(x2) #(11, 11, 32)\n",
    "x2 = Flatten()(x2) #(3872)\n",
    "\n",
    "x3 = Add()([x1, x2])\n",
    "x3 = Dense(512, activation='relu')(x3)\n",
    "x3 = Dense(64, activation='relu')(x3)\n",
    "output_layer = Dense(3)(x3)\n",
    "\n",
    "model = Model(inputs=[input_layer_1, input_layer_2], outputs=output_layer)\n",
    "\n",
    "\n",
    "initial_learning_rate, min_learning_rate  = 0.001, 0.000000001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,  # 초기 학습률\n",
    "    decay_steps=10000,      # 학습률을 감소시킬 스텝 수\n",
    "    decay_rate=0.9,         # 학습률을 줄일 비율\n",
    "    staircase=False\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "losses = ['mean_squared_error', 'mean_squared_error', tf.losses.BinaryCrossentropy(), ]\n",
    "loss_weights =  [1, 1, 0.1]\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=losses, loss_weights=loss_weights)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "993a605d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1057/1057 [==============================] - 34s 23ms/step - loss: 1862.2543 - val_loss: 1458.2552\n",
      "Epoch 2/10\n",
      "1057/1057 [==============================] - 21s 20ms/step - loss: 1341.8911 - val_loss: 1301.5817\n",
      "Epoch 3/10\n",
      "1057/1057 [==============================] - 21s 20ms/step - loss: 1252.0693 - val_loss: 1216.1724\n",
      "Epoch 4/10\n",
      "1057/1057 [==============================] - 21s 20ms/step - loss: 1169.2623 - val_loss: 1594.8536\n",
      "Epoch 5/10\n",
      "1057/1057 [==============================] - 21s 20ms/step - loss: 1069.3506 - val_loss: 1206.6265\n",
      "Epoch 6/10\n",
      "1057/1057 [==============================] - 21s 20ms/step - loss: 970.4026 - val_loss: 1115.6079\n",
      "Epoch 7/10\n",
      "1057/1057 [==============================] - 22s 20ms/step - loss: 882.2443 - val_loss: 1541.0095\n",
      "Epoch 8/10\n",
      "1057/1057 [==============================] - 21s 20ms/step - loss: 794.3475 - val_loss: 1122.5950\n",
      "Epoch 9/10\n",
      "1057/1057 [==============================] - 21s 20ms/step - loss: 674.8948 - val_loss: 1081.6191\n",
      "Epoch 10/10\n",
      "1057/1057 [==============================] - 21s 20ms/step - loss: 573.6373 - val_loss: 1163.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28bf0826560>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터를 준비하고 분할\n",
    "# x_train_1 = ch_rsp_list_tr\n",
    "# x_train_2 = fre_list_tr.reshape((5285,100,100,4))\n",
    "# y_train = label1_list_tr  # 타겟 데이터\n",
    "\n",
    "x_train_1, x_val_1, x_train_2, x_val_2, y_train, y_val = train_test_split(np.array(ch_rsp_list), np.array(fre_list).reshape((5285,100,100,4)), np.array(label1_list), test_size=0.2, random_state=my_seed)\n",
    "\n",
    "# 모델 학습\n",
    "batch_size = 4\n",
    "epochs = 10\n",
    "\n",
    "# Define the ModelCheckpoint callback\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'siren_model2.h5',\n",
    "    monitor='val_loss',  # Check based on validation loss|\n",
    "    verbose=1,\n",
    "    save_best_only=True,  # Save only the best model\n",
    "    mode='min'  # Save the model when the validation loss is minimized\n",
    ")\n",
    "\n",
    "# 입력 데이터 목록을 사용하여 모델 학습\n",
    "model.fit([x_train_1, x_train_2], y_train, validation_data=([x_val_1, x_val_2], y_val), batch_size=batch_size, epochs=epochs, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8034f1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 3s 50ms/step\n",
      "\n",
      "x_rmse: 50.2, y_rmse: 31.2\n",
      "\n",
      "Sample 0\n",
      "Actual: [  0. -35.   0.]\n",
      "Predicted: [-36.314972  -60.10395     0.9579242]\n",
      "Sample 1\n",
      "Actual: [115.  71.   0.]\n",
      "Predicted: [28.95109    20.738724   -0.09037858]\n",
      "Sample 2\n",
      "Actual: [75. 45.  0.]\n",
      "Predicted: [ 8.0241837e+01  4.5434059e+01 -4.7613323e-02]\n",
      "Sample 3\n",
      "Actual: [-75.   5.   1.]\n",
      "Predicted: [-45.448067    11.1883545    0.85691184]\n",
      "Sample 4\n",
      "Actual: [65. 15.  0.]\n",
      "Predicted: [-15.57131    40.491215   -0.2916252]\n",
      "Sample 5\n",
      "Actual: [-30.  20.   1.]\n",
      "Predicted: [-16.568935   15.679655    0.5092759]\n",
      "Sample 6\n",
      "Actual: [  0. -85.   1.]\n",
      "Predicted: [-99.45501   28.129692   1.150605]\n",
      "Sample 7\n",
      "Actual: [-140.   30.    1.]\n",
      "Predicted: [-93.74896    17.834906    1.1419313]\n",
      "Sample 8\n",
      "Actual: [115.  15.   1.]\n",
      "Predicted: [75.24126   21.002716   1.0367808]\n",
      "Sample 9\n",
      "Actual: [80. 20.  1.]\n",
      "Predicted: [51.32849    17.8663      0.40869194]\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict([x_val_1, x_val_2])\n",
    "\n",
    "# 실제 y 값과 예측값 비교\n",
    "rmse = np.sqrt(np.mean((y_hat-y_val)**2, axis=0, keepdims=True))\n",
    "print()\n",
    "print(f\"x_rmse: {round(rmse[0][0],1)}, y_rmse: {round(rmse[0][1],1)}\")\n",
    "print()\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Sample\", i)\n",
    "    print(\"Actual:\", y_val[i])\n",
    "    print(\"Predicted:\", y_hat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daded7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zolnon_kernal",
   "language": "python",
   "name": "zolnon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
